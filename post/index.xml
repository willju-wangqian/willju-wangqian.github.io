<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Posts on Wangqian Ju&#39;s website</title>
    <link>/post/</link>
    <description>Recent content in Posts on Wangqian Ju&#39;s website</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Tue, 19 Apr 2022 00:00:00 +0000</lastBuildDate><atom:link href="/post/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>R project first then git</title>
      <link>/2022/04/19/r-project-first-then-git/</link>
      <pubDate>Tue, 19 Apr 2022 00:00:00 +0000</pubDate>
      
      <guid>/2022/04/19/r-project-first-then-git/</guid>
      <description>The primary goal of this blog is to remind me how to link my local R project to a newly created git repo. The content are mainly from the chapter 17 of the book Happy Git and GitHub for the useR by Jennifer Bryan.
Step 1 Get a local R project and its folder ready.
 Step 2 Create github repo
 Step 3 Connect the local R project folder to the remote github repo</description>
    </item>
    
    <item>
      <title>ML Review Summary</title>
      <link>/2022/03/31/ml-review-summary/</link>
      <pubDate>Thu, 31 Mar 2022 22:18:49 -0500</pubDate>
      
      <guid>/2022/03/31/ml-review-summary/</guid>
      <description>Logistic Regression  Assumption  independent no multicollinearity binary observation for the dependent variable linear relationship between the log of odds and predictors  coefficients  log odds increases or odds multiplies by \(e^\beta\)    Random Forest  intro bagging and OOB:  bootstrap aggregation: train DTs with bootstrap samples (with replacement), aggregate by the majority vote out of bag  “random”  random rows: bagging random cols: use random features in DTs’ training  diversity: each DT is trained based on different training data and different features  diverse committee to cast votes relatively robust to multicollinearity  split criteria:  Gini impurity vs Entropy  best split: lowest Gini impurity, lowest entropy  Each node can compute this measurement; if the split decreases the measurement, then split.</description>
    </item>
    
    <item>
      <title>Include C code in R</title>
      <link>/2022/03/31/r-source-c/</link>
      <pubDate>Thu, 31 Mar 2022 22:03:48 -0500</pubDate>
      
      <guid>/2022/03/31/r-source-c/</guid>
      <description>Intro This is a short summary of how to add C source code into an R package. I wrote this a year ago as a course material summary (STAT 580) and believed that I would remember all the basic details forever. Obviously, I was wrong. So I’m not 100 percent sure about the following contents and can only hope that this is still helpful to, I don’t know, at least myself in the future :) Enjoy!</description>
    </item>
    
    <item>
      <title>Introduction to cmpsR package</title>
      <link>/2022/03/31/cmpsr-intro/</link>
      <pubDate>Thu, 31 Mar 2022 21:53:59 -0500</pubDate>
      
      <guid>/2022/03/31/cmpsr-intro/</guid>
      <description>cmpsR  The cmpsR package is an implementation of the Congruent Matching Profile Segments (CMPS) method (Chen et al. 2019). In general, it can be used for objective comparison of striated tool marks, but in our examples, we mainly use it for bullet signatures comparison. The CMPS score is expected to be large if two signatures are similar. So it can also be considered as a feature that measures the similarity of two bullet signatures.</description>
    </item>
    
  </channel>
</rss>
